<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Rete | 平凡的世界]]></title>
  <link href="http://linuxlsx.github.io/blog/categories/rete/atom.xml" rel="self"/>
  <link href="http://linuxlsx.github.io/"/>
  <updated>2019-07-02T23:25:25+08:00</updated>
  <id>http://linuxlsx.github.io/</id>
  <author>
    <name><![CDATA[linuxlsx]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Arts-week-six]]></title>
    <link href="http://linuxlsx.github.io/blog/2019/04/28/arts-week-six/"/>
    <updated>2019-04-28T21:50:10+08:00</updated>
    <id>http://linuxlsx.github.io/blog/2019/04/28/arts-week-six</id>
    <content type="html"><![CDATA[<h2>Algorithm</h2>

<p>本周完成的算法题: <a href="https://leetcode.com/problems/permutations/">Permutations</a></p>

<p>题目要求:</p>

<pre><code>给定一个不重复的整数数组，求所有可能的排列
</code></pre>

<!-- more -->


<p>本题可以通过回溯法来解决，需要注意排除重复添加元素的情况</p>

<pre><code class="Java">    public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) {
        List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;&gt;();
        backtrack(nums, lists, new ArrayList&lt;&gt;());

        return lists;
    }

    private void backtrack(int[] nums, List&lt;List&lt;Integer&gt;&gt; lists, List&lt;Integer&gt; stack) {
        if (stack.size() == nums.length) {
            lists.add(new ArrayList&lt;&gt;(stack));
        } else {
            for (int i = 0; i &lt; nums.length; i++) {
                if (stack.contains(nums[i])){
                    continue;
                }
                stack.add(nums[i]);
                backtrack(nums, lists, stack);
                stack.remove(stack.size() - 1);
            }
        }
    }
</code></pre>

<h2>Review</h2>

<p>本周Review <a href="https://medium.com/javarevisited/java-8-parallel-stream-java2blog-e1254e593763">Introduction to Java 8 Parallel Stream</a></p>

<p>本文主要讲述了什么时候应该使用<code>Parallel Stream</code>。文中提到<code>Parallel Stream</code>要比<code>Sequential Stream</code> 花费更多的时间在线程协调上，所以在使用<code>Parallel Stream</code> 之前你需要考虑一下的几个因素：</p>

<ul>
<li>要处理的数据集要大</li>
<li>Java使用<code>ForkJoinPool</code>来达到并行的目的。所以源头的集合要可切分(Splitable)，ArrayList 要比 LinkedList 要好</li>
<li>现在确实有性能上的问题</li>
<li>要处理好数据共享的问题</li>
</ul>


<p>通过<code>NQ</code>模型(来自 Brian Goetz)可以衡量是否要做并行化：</p>

<pre><code>N x Q &gt; 10000
</code></pre>

<p>其中：</p>

<p>N = 数据集中的条目数量（number of items in the dataset）
Q = 每个条目需要的工作（amount of work per item）</p>

<p>解释起来就是：如果数据集多但是每个条目需要工作少，或者数据集不多但是每个条目需要的工作多，你就可以通过并行化来获的性能上的优化。</p>

<h2>Tip</h2>

<p>上面Review提到<code>Parallel Stream</code>使用到了<code>ForkJoinPool</code>，这中间一个小细节需要注意：</p>

<p>默认情况下所有的<code>Parallel Stream</code>都是共用<code>ForkJoinPool.common</code>这个池子，所以如果Stream后的任务比较耗时(比如有网络请求等)，会堵塞住整个池子，导致其他的Stream也会被影响到。</p>

<p>如果不想被其他的影响也不想影响其他，可以通过自定有的池子来执行。以下是一个示例:</p>

<pre><code class="Java">    long firstNum = 1;
    long lastNum = 1000000;

    List&lt;Long&gt; aList = LongStream.rangeClosed(firstNum, lastNum).boxed()
      .collect(Collectors.toList());

    ForkJoinPool customThreadPool = new ForkJoinPool(4);
    long actualTotal = customThreadPool.submit(
      () -&gt; aList.parallelStream().reduce(0L, Long::sum)).get();
</code></pre>

<p>参考:</p>

<p><a href="https://dzone.com/articles/think-twice-using-java-8">Think Twice Before Using Java 8 Parallel Streams</a></p>

<p><a href="https://stackoverflow.com/questions/21163108/custom-thread-pool-in-java-8-parallel-stream">Custom thread pool in Java 8 parallel stream</a></p>

<h2>Share</h2>

<p>在项目中碰到了一个因为超大规模的数据(30亿)导致原本执行挺快的模块连续执行超过1天也没有执行完，而且也看不到执行完的希望。于是开始排查是哪里出现了问题。</p>

<h3>背景描述</h3>

<p>业务方基于业务需要配置了约11000条规则，每个规则都是对某个实体的属性判断，最终保存到系统是类似如下的表达式:</p>

<pre><code>"1":"((product_word = '育儿书') OR (product_word = '故事书' AND press = '故事会') OR (product_word = '绘画' AND author = '绘画大师') OR (product_word = '益智游戏类图书') OR (product_word = '儿童读物') OR (product_word = '启蒙认知类图书'))
</code></pre>

<p>我们需要给出每个规则会命中哪些数据，或者说每条数据会命中哪些规则。</p>

<h3>原始方案</h3>

<p>在最开始的实现中，我们是把规则当做一个求值表达式，通过内部的一个DSL引擎对每个规则来做判断，如果返回<code>true</code>就说明命中规则，如果是<code>false</code>说明没有命中规则。</p>

<p>单条规则每次求值时间在<strong>0.04ms</strong>，11000条规则每次执行需要<strong>44ms</strong>左右，在个人机器上测试10w条数据需要大概<strong>4000s</strong>，这个时间完全不可接受的。</p>

<h3>分析问题</h3>

<p>经过数据分析发现就是无效的规则执行太多了，在数据确定的情况下，很多规则是肯定不会命中的。比如有一条数据是这样的:</p>

<pre><code>product_word = 育儿书
press = 中信出版社
author = 小蘑菇
</code></pre>

<p>那它实际需要执行的规则是那些规则条件中包含了 育儿书、中信出版社、小蘑菇的规则，至于其他不包含这些的规则肯定是不会命中的，也就无需执行了。</p>

<p>所以解决方案是：预先为属性、属性值、规则之间建立类似倒排索引的结构，通过属性值来查找可能要执行的规则，然后再执行。</p>

<h3>解决方案</h3>

<p>在解决方案细节中我们需要额外考虑的一点是操作符的问题。对于不同的操作符需要做不同的设计:</p>

<ul>
<li>对于 <strong>Equal(=)</strong> 是可以直接通过值来获取到所有有关系的规则。</li>
<li><code>&gt;</code> <code>&gt;=</code> <code>&lt;</code> <code>&lt;=</code> <code>in</code> <code>not in</code> 等操作符需要做进步一求值才行，但是考虑这些操作符总体使用数量很少，那就直接把这些规则都加到候选规则集中，由求值引擎统一执行即可。</li>
</ul>


<p>假设我们现在有三个属性 product_word，press，author 以及两个操作符 <code>=</code> <code>in</code>，那么最终构成的索引结构如下图：</p>

<p><img src="https://0bb6ac2.oss-cn-hongkong.aliyuncs.com/image/%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E%E4%B8%8E%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E8%9E%8D%E5%90%88-%E6%B1%82%E5%80%BC%E4%BC%98%E5%8C%96.png?x-oss-process=style/black" alt="倒排索引" /></p>

<p>上下层级之间实现都是一个HashMap结构，可以快速的定位到目标数据。有了这个结构后再来看看当输入以下这条数据的时候，需要执行哪些规则：</p>

<pre><code>product_word = 育儿书
press = 中信出版社
author = 小蘑菇
</code></pre>

<ul>
<li>通过 <code>product_word = 育儿书</code> 可以找到规则 <code>R:1</code></li>
<li><code>product_word</code> 还有一个 <code>in</code> 操作符，根据前面提到的原则把这个操作符关联的规则全部加入候选集。现在的规则包含  <code>R:1</code> <code>R:2</code></li>
<li>通过 <code>press = 中信出版社</code> 可以找到规则 <code>R:1</code></li>
<li>通过 <code>author = 小蘑菇</code> 可以找到规则 <code>R:1</code></li>
</ul>


<p>最后要执行的规则集为 <code>[R:1, R:2]</code>，比原来的方案要少执行了规则<code>R:3</code>。</p>

<p>使用这个方案后实际上一条数据最多可能需要执行的规则为<code>100条</code>，更多的少于<code>10条</code>。在本地测试同样执行10w条数据，只需要<strong>27s</strong>，性能提升将近<strong>150倍</strong>。</p>

<h3>总结</h3>

<p>在大规模数据处理中，尽可能的<strong>减少输入数据量</strong>，<strong>减少关键步骤执行次数和时间</strong>是优化性能的两大利器。</p>
]]></content>
  </entry>
  
</feed>
