<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Arts | 平凡的世界]]></title>
  <link href="http://linuxlsx.github.io/blog/categories/arts/atom.xml" rel="self"/>
  <link href="http://linuxlsx.github.io/"/>
  <updated>2019-04-14T00:08:40+08:00</updated>
  <id>http://linuxlsx.github.io/</id>
  <author>
    <name><![CDATA[linuxlsx]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Arts-week-four]]></title>
    <link href="http://linuxlsx.github.io/blog/2019/04/14/arts-week-four/"/>
    <updated>2019-04-14T00:06:02+08:00</updated>
    <id>http://linuxlsx.github.io/blog/2019/04/14/arts-week-four</id>
    <content type="html"><![CDATA[<h2>Algorithm</h2>

<p>本周完成的算法题: <a href="https://leetcode.com/problems/first-missing-positive/">First Missing Positive</a></p>

<p>本题非独立完成，根据<a href="https://stackoverflow.com/questions/1586858/find-the-smallest-integer-not-in-a-list">Find the Smallest Integer Not in a List</a> 参考实现</p>

<p>题目要求:</p>

<pre><code>给定一个没有排序的Int数组，做到数组中不存在的最小正整数。

Note:
1. 算法复杂度必须是O(n)
2. 使用常数个额外的空间
</code></pre>

<p><strong>分析:</strong></p>

<p>这个题的解法很巧妙，通过利用数组的下标和其对应的值做比较就可以确定确实的最小正整数。算法运行时间至多为<code>O(3N)</code>，而且只需要一个额外的Int变量。</p>

<pre><code class="Java">    public int firstMissingPositive(int[] nums) {

        int p;
        //第一个O(N)
        for (int i = 0; i &lt; nums.length; i++) {
            p = nums[i];

            //为什么这里也只会最多执行O(N)次
            //因为在条件中会判断 nums[p - 1] != p，然后在循环体里面会设置 nums[p - 1] = p
            //那么每执行一次赋值，就会减少一个可赋值的位置。
            //就可以保证至多执行N次
            while (p &gt; 0 &amp;&amp; p &lt; nums.length &amp;&amp; nums[p - 1] != p) {
                nums[i] = nums[p - 1];
                nums[p - 1] = p;
                p = nums[i];
            }
        }

        //第三个O(N)
        for (int i = 0; i &lt; nums.length; i++) {
            if (i + 1 != nums[i]) {
                return i + 1;
            }
        }

        ////只有数组是 [1,2,3,4] 这种情况才会走到这里
        return nums.length + 1;
    }
</code></pre>

<h2>Review</h2>

<p>本周Review <a href="https://medium.com/s/story/reflections-on-clean-code-8c9b683277ca">What is Clean Code?</a></p>

<p>本文是作者对于《Clean Code》一书的总结，从他的视角来看，可以归纳总结为三点:</p>

<ul>
<li><strong>工匠精神(Craftsmanship Matters)</strong> 可以<code>Works</code>的代码并不能说已经<code>done</code>，粗制滥造的代码会比你想象的快的出现问题。(Poorly crafted code frays at the edge much faster than you might expect.)</li>
<li><strong>今天的额外努力会减少明天的痛苦(Extra Effort Today Saves Pain Tomorrow)</strong> 就跟买衣服，鞋子一样，好的鞋子可能在价格上会高些，但是它可以穿两年、三年甚至十年，那么长远来看，这个价格就不高了。高质量的代码也是一样的，可以在开始时会困难些，但是会降低未来的技术债和维护成本。</li>
<li><strong>你写的代码不仅仅是你的(Your Code Is Not Your Own)</strong> 过于聪明的把戏，黑科技和编程技巧只是当时作者的乐趣(Overly clever tricks, hacks, and sleights of programmatic hand are only fun for the author.)，但是会给后续的维护者(也可能是你自己)带来无数的麻烦。</li>
</ul>


<p>对于什么是<code>Clean Code</code>，也总结了一下几点:</p>

<ul>
<li>Clean code is simple。虽然可能在算法或者系统层级上复杂，但是实现上要简单。少用比较冷门的技巧。</li>
<li>Clean code is readable。在命名规范、缩进、结构和流程要有良好的设计，虽然显得有些古板但是会减少后来着的理解难度。</li>
<li>Clean code is considerate。Clean code 要为后续的读者考虑，可以假设他们也是拥有同样背景和经验的人。</li>
<li>Clean code is tested。Clean code 要有充分的测试</li>
<li>Clean code is practiced。Clean code 需要多练习</li>
<li>Clean code is relentlessly refactored。Clean code 需要经常重构</li>
<li>Clean code is SOLID。遵循<a href="https://medium.com/@severinperez/writing-flexible-code-with-the-single-responsibility-principle-b71c4f3f883f">Solid 原则</a></li>
</ul>


<p>结合自身的实际来说，我觉得最重要的是 <code>tested</code> 和 <code>readable</code>。只有测试过的代码才能保证联调、测试和线上运行的时候不出现问题。另外很少有情况是你一直维护一套代码，所以让代码有良好的可读性会对后来者有很大帮助，同时自己也会有成就感。</p>

<h2>Tip</h2>

<p>本周分享一个线上排查问题时需要将日志内容按照不同的要求写到不同的文件。</p>

<pre><code class="Shell">awk -F',' '{if ($2 ==1) print $1 &gt; "down.txt"; else if($2 == 6) print $1 &gt; "delete.txt"; else print $1 &gt; "other.txt"}' xxx.log
</code></pre>

<h2>Share</h2>

<p><strong>主要负载均衡算法</strong></p>

<p>分布式场景下client 访问 server 的策略有很多，典型的有 轮询，随机，Hash，最少连接，响应速度，加权算法等。</p>

<p><strong>轮询算法</strong>：将所有请求，依次分发到每台服务器上。缺点: 所有机器的请求一样， 处理能力慢的机器压力变大。
<strong>随机算法</strong>：请求随机分配到各个服务器。简单。缺点：理论上所有机器的请求一样，处理能力慢的机器压力变大。
<strong>最少连接</strong>：将请求分配到连接数最少的服务器（目前处理请求最少的服务器）。优点：根据服务器当前的请求处理情况，动态分配。缺点: 实现比较复杂，需要感知服务器的状态
<strong>Hash</strong> : 根据IP地址进行Hash计算，得到IP地址。优点： 将来自同一IP地址的请求，同一会话期内，转发到相同的服务器；实现会话粘滞。缺点：机器变化时会需要重新计算，最坏情况下所有请求都需要变化。
加权算法：在轮询，随机，最少链接，Hash’等算法的基础上，通过加权的方式，进行负载服务器分配。优点：根据权重，调节转发服务器的请求数目；缺点：使用相对复杂；
<strong>一致性 Hash</strong> ：一致性Hash 的实现是将 node 映射到一个 固定长度的圆环上，请求计算出Hash值按照预定的规则（一般是按照顺时钟方向）落到最近的服务器上。这样当出现机器的变化时，只会影响受影响机器与该机器反方向最近有效服务器之间的节点。其他的节点不会收到影响。当新增node时，只需要计算出该node的hash地址，然后将node 添加到 环的对应位置，只有新node 与后一个node之间的数据会受到影响。这种设计下的扩展性和容错性都比较好。比较不好的问题是在服务器比较少的情况下容易出现负责不均和的情况下。</p>

<p>一致性Hash 的实现是将 node 映射到一个 固定长度的圆环上，并在有效节点中引入多个虚节点（每个虚节点都是有效的的一个影子）。这个所有请求能够均匀的落到node上。</p>

<p>在现在的一致性hash实现上，Google 的研究人员发现在多次负载均衡过后不能够获得最优的负载均衡的效果，开发一个带负载因子(a)的一致性hash算法。</p>

<p>这个算法的能够保证一致性和负责的均衡性（所有的机器的load 都是平均load 的 （1+a）倍）。当出现机器的新增和删除后，通过节点移动的操作重新使得负载重新达到均衡，而这个移动的次数只跟负载因子(a)相关，而与实际节点数的多少无关。每个新增或者删除节点的动作只会导致  O(1/a2) 次其他节点的移动。</p>

<p>更多一致性Hash参考 : <a href="https://juejin.im/post/5b8f93576fb9a05d11175b8d">一致性Hash在负载均衡中的应用</a> </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Arts-week-three]]></title>
    <link href="http://linuxlsx.github.io/blog/2019/04/08/arts-week-three/"/>
    <updated>2019-04-08T00:00:13+08:00</updated>
    <id>http://linuxlsx.github.io/blog/2019/04/08/arts-week-three</id>
    <content type="html"><![CDATA[<h1>Algorithm</h1>

<p>本周完成的算法题: <a href="https://leetcode.com/problems/combination-sum/">Combination Sum</a></p>

<p>题目要求:</p>

<pre><code>给定一个不重复的数组(candidates)，以及一个目标(target)，从candidates找到所有的不重复的组合使得他们的和等于target。

Note:
1. 所有的数字都是正整数
2. 同一个数字可以无限次的重复使用
</code></pre>

<!--more-->


<p><strong>分析:</strong></p>

<p>这题可以通过回溯法来解决，通过递归下降多次遍历数组来寻找满足条件的组合。</p>

<pre><code class="Java">public class CombinationSum {

    public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) {

        List&lt;List&lt;Integer&gt;&gt; lists = new ArrayList&lt;&gt;(8);

        Stack&lt;Integer&gt; stack = new Stack&lt;&gt;();
        stack.ensureCapacity(candidates.length);
        calc(candidates, target, 0,new Stack&lt;&gt;(), lists);

        return lists;
    }

    /**
     * 递归下降深度优先遍历。 算法复杂度 O((n^2 + n) / 2)
     * 最终结果是 6ms  beats 92%
     *
     * 分析了排在更前面的实现，发现主要的差异就是他们用List替代了Stack
     * 来保存中间状态，这样可以减少一个subList的操作。基本上可以到2ms
     *
     * @param candidates
     * @param target
     * @param start
     * @param stack         需要使用栈来保存中间状态。
     * @param lists
     */
    private void calc(int[] candidates, int target, int start, Stack&lt;Integer&gt; stack, List&lt;List&lt;Integer&gt;&gt; lists){

        for (int i = start; i &lt; candidates.length; i++) {

            if(candidates[i] &gt; target){
                continue;
            }

            stack.push(candidates[i]);
            if(candidates[i] == target){
                List&lt;Integer&gt; l = new ArrayList&lt;&gt;(stack.size());
                l.addAll(stack.subList(0, stack.size()));
                lists.add(l);
            }else if(candidates[i] &lt; target) {
                calc(candidates, target - candidates[i], i ,stack , lists);
            }
            stack.pop();
        }
    }
}    
</code></pre>

<h1>Review</h1>

<p>本周Review <a href="https://medium.com/netflix-techblog/building-and-scaling-data-lineage-at-netflix-to-improve-data-infrastructure-reliability-and-1a52526a7977">Building and Scaling Data Lineage at Netflix to Improve Data Infrastructure Reliability, and Efficiency</a></p>

<p>本文是Netflix的一篇技术文章。讲述了Netflix内部是如何构建一个数据链路关系系统的。</p>

<p>公司从小到大的过程中，一定会伴随着数据越来越多，数据链路越来越复杂。很快就没有人能够了解数据全貌了。文章开篇提了三个场景:</p>

<ul>
<li>假设你是一个决策者，当你要根据数据看报做一个关键决策时，是否可以自己去验证下看报背后的数据到底是什么</li>
<li>假设你是一个开发者，当你决定要修改你提供的服务的数据结构时，是否可以知道哪些下游会受到影响</li>
<li>假设你现在负责平台的可靠性，你的任务是主动监测上游任务的问题，提前给数据作业owner报警。你要设计一个SLA预警系统，需要用到上下游数据依赖以及历史状态数据。<code>(Finally, imagine yourself in the role of a data platform reliability engineer tasked with providing advanced lead time to data pipeline (ETL) owners by proactively identifying issues upstream to their ETL jobs. You are designing a learning system to forecast Service Level Agreement (SLA) violations and would want to factor in all upstream dependencies and corresponding historical states)</code></li>
</ul>


<p>要满足以上的需求，就需要有一个 <code>complete and accurate data lineage system</code>。</p>

<p>自由和责任是Netflix内部文化的重要部分。核心思想是你可以自由的选择实现方式，但是要为其负责。同样这样的自由也会导致公司内部技术栈的多样性，同样也会带来更多的负责度。作者就面临这样的问题。以下是Netflix 的一个<code>Data Landscape</code>。</p>

<p><img src="https://cdn-images-1.medium.com/max/1400/0*gYI3uCywVhSrcoRo" alt="Data Landscape" /></p>

<p>为了满足Netflix内部多样化的数据，<code>Data Lineage</code>有以下的几个设计原则：</p>

<ul>
<li><code>Ensure data integrity</code> 数据完整性。 需要精确完整的保存数据关系来建立用户的信心。一个不完全可行系统带来伤害可能多过好处。</li>
<li><code>Enable seamless intergration</code> 无缝接入。需要能够满足新的数据工具快速接入。</li>
<li><code>Design a flexible data model</code> 灵活的数据结构。使用一个通用灵活的数据模型来表示不同的数据来源。</li>
</ul>


<p>最终的系统实现图如下：</p>

<p><img src="https://cdn-images-1.medium.com/max/2600/0*Xp1KHPFm1R7GZGAI" alt="系统实现图" /></p>

<p>解释下这个图：</p>

<p>首先左侧是数据接入层，每个业务系统都有它自己独立数据处理逻辑，独立的数据模型。所以在使用之前需要统一进行转换。</p>

<p>中间一层就是数据转换层，转换层将所有收集上来的数据进行转换，统一用点和边的图模式表达。数据转换完毕后会将数据存储到图数据库中。</p>

<p>右侧就是数据存储和服务层。在数据之上建立了的REST服务层，对外提供数据服务。</p>

<h1>Tip</h1>

<p>在Java中很多情况需要对一些特殊字符做一些转义。那么一般的写法就是为罗列出所有的需要进行替换的字符，然后不停的调用replace。比如像下面的代码：</p>

<pre><code class="Java">keyword.replace("\\", "\\\\").replace("*", "\\*")
                .replace("+", "\\+").replace("|", "\\|")
                .replace("{", "\\{").replace("}", "\\}")
                .replace("(", "\\(").replace(")", "\\)")
                .replace("^", "\\^").replace("$", "\\$")
                .replace("[", "\\[").replace("]", "\\]")
                .replace("?", "\\?").replace(",", "\\,")
                .replace(".", "\\.").replace("&amp;", "\\&amp;")
                .replace("-", "\\-");
</code></pre>

<p>这样写虽然能够完成需求，但是不太优雅。在Java的正则表达式中实际是可以支持类似<code>$0 $1</code>这样的占位符的。那么像<code>.replace("[", "\\[")</code> 可以改写成 <code>.replace("[", "\\$0")</code>。</p>

<p>在这个实现中，<code>$0</code> 代表的是整个正则的匹配结果，<code>$1 $2...$n</code> 代表的是从1-n的捕获组的内容。</p>

<p>具体的捕获组的介绍可以参考：<a href="https://blog.csdn.net/just4you/article/details/70767928">正则表达式的捕获组(capture group)在Java中的使用</a></p>

<p>上面的语句改成类似形式的案例：</p>

<pre><code class="Java">String s = "\\*+|{}^$[]?,.&amp;-";
System.out.println(s);
System.out.println(s.replaceAll("[\\\\\\*\\+\\|\\{\\}\\(\\)\\^\\$\\[\\]\\?\\,\\.\\&amp;\\-]", "\\\\$0"));

//输出
\*+|{}^$[]?,.&amp;-
\\\*\+\|\{\}\^\$\[\]\?\,\.\&amp;\-
</code></pre>

<h1>Share</h1>

<p><a href="http://linuxlsx.top/blog/2019/04/07/la-ji-hui-shou-de-suan-fa-yu-shi-xian-du-shu-bi-ji-fu-zhi-suan-fa/">GC算法-复制算法</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Arts-week-two]]></title>
    <link href="http://linuxlsx.github.io/blog/2019/03/29/arts-week-two/"/>
    <updated>2019-03-29T21:25:12+08:00</updated>
    <id>http://linuxlsx.github.io/blog/2019/03/29/arts-week-two</id>
    <content type="html"><![CDATA[<h1>ARTS 第2周</h1>

<h2>Algorithm</h2>

<p>本周完成的算法题: <a href="https://leetcode.com/problems/valid-sudoku/">Valid Sudoku</a></p>

<p>题目要求:</p>

<pre><code>通过二维数组定义了9x9的数独库，这个数独库的某些位置会被数字填充，其他地方填充'.'，现在需要你来验证这个数独库是否合法的。有效数独的规则如下:

1. 每一行都是1-9不重复的数字
2. 每一列都是1-9不重复的数字
3. 每一个3x3的小方格中也是1-9不重复的数字
</code></pre>

<!-- more -->


<p><strong>分析:</strong></p>

<p>要完成有效性的判定，双重循环遍历是肯定要的。我们需要考虑的是如何只使用双重循环就把所有事情搞定。通过对矩阵的观察，我们发现有以下的规律:</p>

<ul>
<li>当我们访问<code>soduku[i][j]</code>，通过转换顺序<code>soduku[j][i]</code>，这样可以同时访问一行、一列。</li>
<li>可以通过 <code>(i / 3) 和 (j / 3)</code>得到一个<code>3x3</code>小方格，同时通过<code>(i % 3) * 3 + j % 3</code>计算出<code>sudoku[i][j]</code>在小方格中的位置。</li>
</ul>


<p>通过以上两个规律，我们就可以在<code>n * n</code>次循环中得出是否合法的结果。</p>

<pre><code class="Java">class Solution {
    public boolean isValidSudoku(char[][] board) {

        //实现的比较挫，这里定了9个数组用来代表9个 3x3的小方格
        char[] rect0 = {'.','.','.','.','.','.','.','.','.'};
        char[] rect1 = {'.','.','.','.','.','.','.','.','.'};
        char[] rect2 = {'.','.','.','.','.','.','.','.','.'};
        char[] rect3 = {'.','.','.','.','.','.','.','.','.'};
        char[] rect4 = {'.','.','.','.','.','.','.','.','.'};
        char[] rect5 = {'.','.','.','.','.','.','.','.','.'};
        char[] rect6 = {'.','.','.','.','.','.','.','.','.'};
        char[] rect7 = {'.','.','.','.','.','.','.','.','.'};
        char[] rect8 = {'.','.','.','.','.','.','.','.','.'};

        Map&lt;String, char[]&gt; maps = new HashMap&lt;&gt;();
        maps.put("0_0", rect0);
        maps.put("0_1", rect1);
        maps.put("0_2", rect2);
        maps.put("1_0", rect3);
        maps.put("1_1", rect4);
        maps.put("1_2", rect5);
        maps.put("2_0", rect6);
        maps.put("2_1", rect7);
        maps.put("2_2", rect8);

        for (int i = 0; i &lt; 9; i++) {
            char[] hor_array = {'.','.','.','.','.','.','.','.','.'};
            char[] ver_array = {'.','.','.','.','.','.','.','.','.'};
            for (int j = 0; j &lt; 9; j++) {
                //行
                char hor_char = board[i][j];
                //列
                char ver_char = board[j][i];

                //如果第一次出现，则把对应的位置替换为对应的内容
                //如果第二次出现，那么内容就不是初始值了，可以认定是invalid
                if(hor_char != '.'){
                    if(hor_array[hor_char - '0'] == '.'){
                        hor_array[hor_char - '0'] = hor_char;
                    }else {
                        return false;
                    }

                    //计算当前位置所属的小方格
                    String key = (i / 3) + "_" + (j / 3);
                    //int index = (i % 3) * 3 + j % 3;
                    char[] rect = maps.get(key);
                    if (rect[hor_char - '0'] == '.') {
                        rect[hor_char - '0'] = hor_char;
                    }else {
                        return false;
                    }
                }

                if(ver_char != '.'){
                    if(ver_array[ver_char - 49] == '.'){
                        ver_array[ver_char - 49] = ver_char;
                    }else {
                        return false;
                    }
                }
            }
        }

        return true;
    }
}
</code></pre>

<p>实现思路上算是正确的，但不是最优的哈。最优代码参考:</p>

<pre><code class="Java">    /**
     * 最快的版本。 10ms  beats 100%。
     * 对于每个横、竖和3x3 进行 `|` 操作，这样通过 `&amp;`操作就能知道这个数字是否重复过。
     * @param board
     * @return
     */
    public boolean isValidSudokuFastest(char[][] board) {

        int [] vset = new int [9];
        int [] hset = new int [9];
        int [] bckt = new int [9];
        int idx = 0;
        for (int i = 0; i &lt; 9; i++) {
            for (int j = 0; j &lt; 9; j++) {
                if (board[i][j] != '.') {
                    idx = 1 &lt;&lt; (board[i][j] - '0') ;
                    if ((hset[i] &amp; idx) &gt; 0 ||
                            (vset[j] &amp; idx) &gt; 0 ||
                            (bckt[(i / 3) * 3 + j / 3] &amp; idx) &gt; 0) return false;
                    hset[i] |= idx;
                    vset[j] |= idx;
                    bckt[(i / 3) * 3 + j / 3] |= idx;
                }
            }
        }
        return true;

    }
</code></pre>

<h2>Review</h2>

<p>本周Review <a href="https://medium.com/s/story/the-law-of-two-thirds-cfad7c4d42eb">A Technique for Deciding When to Say No</a></p>

<p><code>人不能完成所有事情，所以我们需要对要做的事情，想要的东西做取舍。当你选择某些项的时候，也就舍弃了其他的</code></p>

<p>文章中提出了一个<code>2-3</code>法则，就是说在3个关键要素中，你只能同时选择两个。比如：质量、速度和价格，只能选择两个。如果你想要质量和速度，那么价格必然就贵；你想要低价同时也想保持质量，那么速度必然受到影响；你想要低价和速度，那么质量就无法保证。</p>

<p>这个观点和我们程序员熟悉的<code>CAP</code>理论有异曲同工之妙，同样的三个要素，不可兼得。</p>

<p>那么怎么样来进行选择呢？那么首先要弄明白的是你想要的到底是什么？这里要记住：<code>你是不可能做所有事情，得到所有东西的</code>。</p>

<p>对于生活，一定不要让自己时时处于忙碌的状态，忙碌意味着你不知道你想要的是什么，你不知道对什么说<strong>不</strong>，所以你的时间被无关的事情给占有了。</p>

<h2>Tip</h2>

<p><strong>在数据量大的情况下，任何系统的性能隐患都被放大直到系统崩溃。</strong></p>

<p>在本周有一个算法同学写了一段类似如下的大数据处理SQL：</p>

<pre><code class="SQL">select col1, col2, process(col4, map('{1,2,3,4,5}')) from table_a
</code></pre>

<p>SQL 很简单，<code>process</code> 和 <code>map</code>都是自定的函数。其中<code>map</code>函数会将参数转化成一个map结构。但是在实际运行的时候发现性能很差，100亿条数据执行了9个多小时。他找我帮他看看问题在哪里？</p>

<p>问题其实就是<code>map</code>函数导致的，这个sql每处理一条数据就会调用<code>map</code>函数，就会创建一个新对象。同时因为参数比较长，会多次触发map的扩容，导致整个SQL执行99%以上的时间其实在创建map和扩容中。</p>

<p>当修改实现改成使用缓存以后，性能溜得飞起，只要了<strong>4分钟</strong>就完成了。</p>

<p>在大数据环境下，对象的创建其实是很昂贵的操作。所以像<code>Hadoop</code>这样的大数据框架才会设计成对象复用。</p>

<h2>Share</h2>

<p><a href="http://linuxlsx.top/blog/2019/03/26/la-ji-hui-shou-de-suan-fa-yu-shi-xian-du-shu-bi-ji-yin-yong-ji-shu-fa/">GC算法-引用计数法</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ARTS First Week]]></title>
    <link href="http://linuxlsx.github.io/blog/2019/03/21/arts-first-week/"/>
    <updated>2019-03-21T23:09:03+08:00</updated>
    <id>http://linuxlsx.github.io/blog/2019/03/21/arts-first-week</id>
    <content type="html"><![CDATA[<h1>ARTS 第1周</h1>

<h2>Algorithm</h2>

<p>本周完成的算法题: <a href="https://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array/">Find First and Last Position of Element in Sorted Array</a></p>

<p>题目要求:</p>

<pre><code>Given an array of integers nums sorted in ascending order, find the starting and ending position of a given target value.

Your algorithm's runtime complexity must be in the order of O(log n).

If the target is not found in the array, return [-1, -1].
</code></pre>

<p><strong>分析:</strong></p>

<p>在<code>O(log n)</code> 时间复杂度的限制下，肯定是要用二分查找的。但是与普通的查找不同，这个题目实际的要求是查找目标的<code>左边界</code>和<code>右边界</code>。这样我们通过二分法查找到目标值以后，<strong>不能立刻返回</strong>，而是要继续向左或者向右查看是否有更左或者更右的目标。所以通过两次二分查找即可得到想要的结果。时间复杂度为 <code>2 * O(log n)</code></p>

<p>代码实际比较简单，就不贴代码了。</p>

<h2>Review</h2>

<p>本周Review <a href="https://medium.com/s/the-nuance/why-your-brain-needs-idle-time-e5d90b0ef1df">Why Your Brain Needs Idle Time</a></p>

<p><code>适当的休息更有助于学习和消化知识</code></p>

<p>每个人的精力是有限的，每天的工作和社交活动占用了很大的一部分，很多人只有在晚上淋浴和准备睡觉的时候才能让放松下来。</p>

<p>文中研究了<code>适当休息</code>是否会对老鼠过迷宫速度有影响。两只老鼠，一只通过迷宫后会休息下然后再重走一次迷宫，而另一只不休息直接重走。结果表明：休息过的老鼠第二次走迷宫的速度会比不休息的要<strong>快</strong>。</p>

<p>所以，不是总是让自己的大脑处于负荷运行的情况，适当的休息并不会降低效率，相反会提高效率。</p>

<h2>Tip</h2>

<p>在写代码过程中经常会碰到用一个Map来保存(K,V)结构，如果一个K有多个V的时候，我们需要指定<code>List&lt;V&gt;</code>来保存。最近我碰到了一个新的用法，使用<code>apache-commons 4</code>中的 <code>MultiValuedMap</code>可以帮助我们简化代码。</p>

<p>MultiValuedMap 的类结构如下图:</p>

<p><img src="http://0bb6ac2.oss-cn-hongkong.aliyuncs.com/image/multihashmap.jpg?x-oss-process=style/origin" alt="类结构" /></p>

<p>主要提供了两种实现：基于ArrayList的实现和基于HashSet的实现。主要区别就是在于对于<code>Key</code>是否允许重复的<code>V</code>存在。</p>

<h2>Share</h2>

<p><a href="http://linuxlsx.top/blog/2019/03/21/guan-jian-ci-pi-pei-suan-fa-diao-yan/">关键词匹配算法调研</a></p>
]]></content>
  </entry>
  
</feed>
